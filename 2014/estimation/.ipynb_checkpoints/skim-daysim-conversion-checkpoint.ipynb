{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract skim values based on Daysim attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load daysim trip records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daysim = h5py.File(r'R:\\SoundCast\\estimation\\2014\\P5\\survey14.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_df(h5file, h5table, var_dict, survey_file=False):\n",
    "    ''' Convert H5 into dataframe '''\n",
    "    data = {}\n",
    "    if survey_file:\n",
    "        # survey h5 have nested data structure, different than daysim_outputs\n",
    "        for col_name, var in var_dict.iteritems():\n",
    "            data[col_name] = [i[0] for i in h5file[h5table][var][:]]\n",
    "    else:\n",
    "        for col_name, var in var_dict.iteritems():\n",
    "            data[col_name] = [i for i in h5file[h5table][var][:]]\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of fields to extract from trip records\n",
    "tripdict={'Household ID': 'hhno',\n",
    "            'Person Number': 'pno',\n",
    "            'Travel Time':'travtime',\n",
    "            'Travel Cost': 'travcost',\n",
    "            'Travel Distance': 'travdist',\n",
    "            'Mode': 'mode',\n",
    "            'Purpose':'dpurp',\n",
    "            'Departure Time': 'deptm',\n",
    "            'Origin TAZ': 'otaz',\n",
    "            'Destination TAZ': 'dtaz',\n",
    "            'Departure Time': 'deptm',\n",
    "            'Expansion Factor': 'trexpfac'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip = build_df(h5file=daysim, h5table='Trip', var_dict=tripdict, survey_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hhdict={'Household ID': 'hhno',\n",
    "        'Household Size': 'hhsize',\n",
    "        'Household Vehicles': 'hhvehs',\n",
    "        'Household Workers': 'hhwkrs',\n",
    "        'Household Income': 'hhincome',\n",
    "        'Household TAZ': 'hhtaz',\n",
    "        'Expansion Factor': 'hhexpfac'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh = build_df(h5file=daysim, h5table='Household', var_dict=hhdict, survey_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join household to trip data to get income\n",
    "trip_hh = pd.merge(trip,hh, on='Household ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a lookup variable to find skim value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_dictionary(input_filename):\n",
    "\n",
    "    my_file=open(input_filename)\n",
    "    my_dictionary = {}\n",
    "\n",
    "    for line in my_file:\n",
    "        k, v = line.split(':')\n",
    "        my_dictionary[eval(k)] = v.strip()\n",
    "\n",
    "    return(my_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix_dict  = text_to_dictionary(r'D:\\tmp\\soundcast-master\\inputs\\skim_params\\demand_matrix_dictionary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bike',\n",
       " 'h2nt1',\n",
       " 'h2nt2',\n",
       " 'h2nt3',\n",
       " 'h2tl1',\n",
       " 'h2tl2',\n",
       " 'h2tl3',\n",
       " 'h3nt1',\n",
       " 'h3nt2',\n",
       " 'h3nt3',\n",
       " 'h3tl1',\n",
       " 'h3tl2',\n",
       " 'h3tl3',\n",
       " 'hvtrk',\n",
       " 'lttrk',\n",
       " 'metrk',\n",
       " 'svnt1',\n",
       " 'svnt2',\n",
       " 'svnt3',\n",
       " 'svtl1',\n",
       " 'svtl2',\n",
       " 'svtl3',\n",
       " 'trnst',\n",
       " 'walk'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueMatrices = set(matrix_dict.values())\n",
    "uniqueMatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Value of Time'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f0751e4cc287>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtestvot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrip_hh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Mode'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Value of Time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Departure Time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Origin TAZ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Destination TAZ'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Toll Class'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1772\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1773\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1774\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1775\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1816\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1818\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1819\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'key'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Value of Time'] not in index\""
     ]
    }
   ],
   "source": [
    "# Add a field for skims based on mode, vot, and tollpath\n",
    "# tollpath is always set to 1?\n",
    "\n",
    "testvot = 2\n",
    "\n",
    "df = trip_hh[['Mode','Value of Time', 'Departure Time','Origin TAZ', 'Destination TAZ']]\n",
    "df['Toll Class'] = np.ones(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(df['VOT Bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['VOT Bin'] = pd.cut(df['Value of Time'], bins=[0,15,25,99999], right=True, labels=[1,2,3], retbins=False, precision=3, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['VOT Bin'] = df['VOT Bin'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert departure time in min after 3 am to hours past midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['min after midnight'] = df['Departure Time'] + 180\n",
    "df['hr after midnight'] = (df['min after midnight']/60).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that hours midnight to 3 am will be recorded as 24-26\n",
    "print max(df['hr after midnight'])\n",
    "print min(df['hr after midnight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lookup for departure time to skim times\n",
    "tod_dict = {\n",
    "    3: '20to5',\n",
    "    4: '20to5',\n",
    "    5: '5to6',\n",
    "    6: '6to7',\n",
    "    7: '7to8',\n",
    "    8: '8to9',\n",
    "    9: '9to10',\n",
    "    10: '10to14',\n",
    "    11: '10to14',\n",
    "    12: '10to14',\n",
    "    13: '10to14',\n",
    "    14: '14to15',\n",
    "    15: '15to16',\n",
    "    16: '16to17',\n",
    "    17: '17to18',\n",
    "    18: '18to20',\n",
    "    19: '18to20',\n",
    "    20: '20to5',\n",
    "    21: '20to5',\n",
    "    22: '20to5',\n",
    "    23: '20to5',\n",
    "    24: '20to5',\n",
    "    25: '20to5',\n",
    "    26: '20to5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hours=np.asarray(df['hr after midnight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['dephr'] = [tod_dict[hours[i]] for i in xrange(len(hours))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['dephr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an ID to match skim naming method\n",
    "mode_dict = {\n",
    "    1: 'walk',\n",
    "    2: 'bike',\n",
    "    3: 'sv',\n",
    "    4: 'h2',\n",
    "    5: 'h3',\n",
    "    6: 'tr',\n",
    "    7: 'ot',\n",
    "    8: 'ot',\n",
    "    9: 'ot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modes=np.asarray(df['Mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['mode code'] = [mode_dict[modes[i]] for i in xrange(len(modes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate for an id\n",
    "df['skim_id'] = df['mode code'] + 'tl' + df['VOT Bin'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open up skims by TOD\n",
    "tods = set(tod_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=h5py.File(r'R:\\SoundCast\\releases\\TransportationFutures2010\\inputs\\7to8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skim_dict = {}\n",
    "working_dir = r'R:\\SoundCast\\releases\\TransportationFutures2010\\inputs'\n",
    "for tod in tods:\n",
    "    contents = h5py.File(working_dir + r'/'+ tod + '.h5')\n",
    "    skim_dict[tod] = contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look up skim values by tod\n",
    "testrecord = df.iloc[0]\n",
    "skim_dict[testrecord['dephr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "for mode in np.unique(df['mode code']):\n",
    "    print \"processing skim lookup ID: \" + mode\n",
    "    mylen = len(df[df['mode code'] == mode])\n",
    "    tempdf = df[df['mode code'] == mode]\n",
    "    if mode not in ['walk','bike']:\n",
    "        tempdf['skim_id'] = tempdf['mode code'] + 'tl' + tempdf['VOT Bin'].astype('str')\n",
    "    else:\n",
    "        tempdf['skim_id'] = tempdf['mode code']\n",
    "    final_df = final_df.append(tempdf)\n",
    "    print 'number of ' + mode + 'trips: ' + str(len(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = final_df; del final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iloc[367577]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open a project to acquire zone numbers\n",
    "from EmmeProject import *\n",
    "my_project = EmmeProject(r'R:\\SoundCast\\releases\\TransportationFutures2010\\projects\\7to8\\7to8.emp')\n",
    "zones=my_project.current_scenario.zone_numbers\n",
    "dictZoneLookup = dict((value,index) for index,value in enumerate(zones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the travel time skims\n",
    "tod = '7to8'\n",
    "test_val= [df['skim_id'] + 't'][0].iloc[0]\n",
    "\n",
    "my_matrix = skim_dict[tod]['Skims'][test_val]\n",
    "\n",
    "my_matrix[dictZoneLookup[4]][dictZoneLookup[5]]\n",
    "\n",
    "# Skim matrix is 0-based\n",
    "# need to lookup zone id based on array index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_matrix[dictZoneLookup[4]][dictZoneLookup[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 6 in [4,5]:\n",
    "    print 'yeah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop through each record\n",
    "bikewalk_tod = '5to6'   # bike and walk are only assigned in 5to6\n",
    "distance_skim_tod = '7to8'\n",
    "\n",
    "output_array = []\n",
    "missing_field=[]\n",
    "for i in range(8000000,8000100):\n",
    "    rowresults = {}\n",
    "    rowdata = df.iloc[i]\n",
    "\n",
    "    # loop through skim types\n",
    "    for skim_type in ['t','c','d']:\n",
    " \n",
    "        # if it's a bike or skim, use 5to6\n",
    "        if rowdata['Mode'] in ['Bike','Walk']:\n",
    "            tod = bikewalk_tod\n",
    "\n",
    "        elif skim_type == 'd':\n",
    "            tod = distance_skim_tod\n",
    "        else:\n",
    "            tod = rowdata['dephr']\n",
    "           \n",
    "        try:\n",
    "            my_matrix = skim_dict[tod]['Skims'][rowdata['skim_id']+skim_type]\n",
    "            otaz=rowdata['Origin TAZ']\n",
    "            dtaz=rowdata['Destination TAZ']\n",
    "            print i\n",
    "            skim_value = my_matrix[dictZoneLookup[otaz]][dictZoneLookup[dtaz]]\n",
    "#             output_array.append(skim_value)\n",
    "            rowresults[skim_type] = skim_value\n",
    "        except:\n",
    "            missing_field.append(rowdata['skim_id']+skim_type)\n",
    "#             output_array.append('-99')\n",
    "            rowresults[skim_type] = '-99'\n",
    "            # append a -99\n",
    "    # append rowresults to master array\n",
    "    output_array.append(rowresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(output_array).to_csv('skim_travel_time_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the skim results csv\n",
    "skimresults = pd.read_csv(r'skim_travel_time_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the trip DAT file (formatted to Daysim by Mark Bradley)\n",
    "trip = pd.read_csv(r'R:\\SoundCast\\estimation\\2014\\P5\\tripP5.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join the skimresults to the original DAT file (trip)\n",
    "joined_data = pd.merge(left=trip,right=skimresults,left_on='tripid',right_on='tripID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace the original field names with values from the joined data and export in standard format\n",
    "joined_data['travcost'] = joined_data['c']\n",
    "joined_data['travdist'] = joined_data['d']\n",
    "joined_data['travtime'] = joined_data['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace -99 (missing data) with -1 to match 2006 survey\n",
    "for field in ['travcost','travdist','travtime']:\n",
    "    joined_data.ix[joined_data[field] == -99, field] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_modified = joined_data[trip.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "save_loc = r'R:\\SoundCast\\estimation\\2014\\P5\\skims_attached'\n",
    "\n",
    "trip_modified.to_csv(save_loc + r'\\tripP5_with_skims.dat', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
