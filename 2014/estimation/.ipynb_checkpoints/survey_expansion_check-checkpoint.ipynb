{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This script is used to expand a survey sample by growing each record according to its expansion weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open 2006 survey data and export as space-delimted field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in h5 data\n",
    "survey06 = h5py.File(r'R:\\SoundCast\\estimation\\2006\\survey06_original.h5', 'r')\n",
    "survey14expanded = h5py.File(r'R:\\SoundCast\\estimation\\2014\\expanded\\hh_and_persons_14.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in survey 14 samples\n",
    "survey14 = pd.read_csv(r'R:\\SoundCast\\estimation\\2014\\hrecP2.dat', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h5_to_df(h5_file):\n",
    "    '''Convert daysim outputs and survey h5 tables into dataframes.\n",
    "        Inputs are expected as tables with single-column sub-tables.'''\n",
    "    dataframes = {}\n",
    "    for data_table in h5_file.keys():\n",
    "        dataframes[data_table] = pd.DataFrame()\n",
    "        # Write each column to a dataframe\n",
    "        for col in h5_file[data_table].keys():\n",
    "            dataframes[data_table][col] = [i[0] for i in h5_file[data_table][col][:]]\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def h5_to_csv(h5_file, output_tag='', overwrite=True):\n",
    "    '''Write daysim outputs and survey h5 tables onto disk.'''\n",
    "    dataframes = h5_to_df(h5_file)\n",
    "    for df in h5_file.keys():\n",
    "        fname = df+output_tag+'.csv'\n",
    "        if overwrite and os.path.isfile(fname):\n",
    "            os.remove(fname)\n",
    "            dataframes[df].to_csv(path_or_buf=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df06 = h5_to_df(survey06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5_to_csv(survey06, '06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df14 = h5_to_df(survey14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df14_expanded = h5_to_df(survey14expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanded households from survey: 1479103.6793\n"
     ]
    }
   ],
   "source": [
    "print 'expanded households from survey: ' +  str(survey14['hhexpfac'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "household records in expansion: 1480090\n"
     ]
    }
   ],
   "source": [
    "print 'household records in expansion: ' + str(df14_expanded['Household'].count()['hhno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples factored up: 7    125.817\n",
      "Name: hhexpfac, dtype: float64\n",
      "expanded results: 126\n"
     ]
    }
   ],
   "source": [
    "# Should be this many rows of entries matching household  in expanded \n",
    "test_hhid = 14100008\n",
    "print 'samples factored up: ' + str(survey14[survey14['hhno'] == test_hhid]['hhexpfac'])\n",
    "\n",
    "print 'expanded results: ' + str(len(df14_expanded['Household'][df14_expanded['Household']['hhno'] == test_hhid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5_to_csv(survey14, '14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hh515       1.355000e+03\n",
       "hhcu5       5.900000e+02\n",
       "hhexpfac    1.375592e+06\n",
       "hhftw       4.281000e+03\n",
       "hhhsc       3.220000e+02\n",
       "hhincome    2.984495e+08\n",
       "hhno        1.176722e+08\n",
       "hhoad       1.465000e+03\n",
       "hhparcel    2.533019e+09\n",
       "hhptw       9.020000e+02\n",
       "hhret       1.374000e+03\n",
       "hhsize      1.051000e+04\n",
       "hhtaz       8.587134e+06\n",
       "hhuni       2.210000e+02\n",
       "hhvehs      8.993000e+03\n",
       "hhwkrs      8.565000e+03\n",
       "hownrent    5.594000e+03\n",
       "hrestype    7.080000e+03\n",
       "samptype    5.752000e+03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the 2014 survey and compare to expanded\n",
    "df14['Household'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the expanded survey h5 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert h5 data into a dictionary of dataframes, with each h5 table as a separate dataframe\n",
    "dataframes = {}\n",
    "for data_table in survey06.keys():\n",
    "    dataframes[data_table] = pd.DataFrame()\n",
    "    # Write each column to a dataframe\n",
    "    for col in survey06[data_table].keys():\n",
    "        dataframes[data_table][col] = [i[0] for i in survey06[data_table][col][:]]\n",
    "    try:\n",
    "        dataframes[data_table].to_csv(path_or_buf=data_table+'06.csv', sep=' ')\n",
    "    except:\n",
    "        print 'could not export output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes['Person'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_content = open('Household' + '06.csv', 'r')\n",
    "lines = np.asarray(data_content.read().split('\\n'))\n",
    "\n",
    "\n",
    "\n",
    "#create a master array, which uses the first line as the form\n",
    "df_array = np.asarray(lines[0].split(' ')) \n",
    "for j in range(1,len(lines)-1): \n",
    "    print data_table + \" \" + str(j)    # print sample row\n",
    "    subarray = np.asarray(lines[j].split(' '))\n",
    "    factor = abs(int(round(float(subarray[-1]),0))) \n",
    "    subarray = [subarray]*factor    #copy the sample 'factor' times\n",
    "    df_array = np.vstack((df_array, subarray)) #merge the expanded sample into the master array\n",
    "\n",
    "expanded_results[data_table] = df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_array = np.asarray(lines[0].split(' '))\n",
    "np.where(df_array == np.fromregex('hh515'))\n",
    "df_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_num = [i for i, s in enumerate(df_array) if 'expfac' in s]\n",
    "df_array[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = 5\n",
    "test = []\n",
    "for j in range(1,x-1):\n",
    "    test.append(j)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(str(df_array[col_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-5b04abc79235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# start at 2 to skip the header row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[0mdata_table\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# print sample row\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0msubarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mfactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_table' is not defined"
     ]
    }
   ],
   "source": [
    "# Synthesize expanded dataset\n",
    "mydir = r'R:\\SoundCast\\estimation\\2014\\hrecP2.dat'\n",
    "\n",
    "# Open each data table and process its contents\n",
    "data_content = open(mydir, 'r')\n",
    "lines = np.asarray(data_content.read().split('\\n'))\n",
    "\n",
    "#create a master array, which uses the first line as the form\n",
    "df_array = np.asarray(lines[0].split(' ')) \n",
    "\n",
    "# column number for expansion factor\n",
    "col_num = [i for i, s in enumerate(df_array) if 'expfac' in s]\n",
    "\n",
    "# for j in range(1,len(lines)-1):\n",
    "for j in range(1,100):\n",
    "    # start at 2 to skip the header row\n",
    "    print j    # print sample row\n",
    "    subarray = np.asarray(lines[j].split(' '))\n",
    "    factor = abs(int(round(float(subarray[col_num][0]),0))) \n",
    "    subarray = [subarray]*factor    #copy the sample 'factor' times\n",
    "    df_array = np.vstack((df_array, subarray)) #merge the expanded sample into the master array\n",
    "\n",
    "output = pd.DataFrame(df_array[1:-1], columns=lines[0].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(expanded_results['Household'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Expand person records\n",
    "person = open('D:/estimation/Household06.csv', 'r')\n",
    "lines = np.asarray(person.read().split('\\n'))\n",
    "\n",
    "#create a master array, which uses the first line as the form\n",
    "df_array = np.asarray(lines[0].split(' ')) \n",
    "for j in range(1,len(lines)-1): \n",
    "    print j\n",
    "    subarray = np.asarray(lines[j].split(' '))\n",
    "    factor = abs(int(round(float(subarray[-1]),0))) \n",
    "    #print factor\n",
    "    subarray = [subarray]*factor #copy the sample 'factor' times\n",
    "    df_array = np.vstack((df_array, subarray)) #merge the expanded sample into the master array\n",
    "    #print len(df_array)\n",
    "print len(df_array)\n",
    "\n",
    "output = pd.DataFrame(df_array[1:-1], columns=lines[0].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################person###############################\n",
    "\n",
    "#output.to_hdf('R:/SoundCast/estimation/2014/survey14_expanded.h5','precp2_expanded',append=True)\n",
    "\n",
    "####################household######################################\n",
    "person=open('R:/SoundCast/estimation/2014/hrecP2.dat', 'r')\n",
    "lines = np.asarray(person.read().split('\\n'))\n",
    "df_array = np.asarray(lines[0].split(' '))\n",
    "for j in range(1,len(lines)-1):\n",
    "    print j\n",
    "    subarray = np.asarray(lines[j].split(' '))\n",
    "    factor = abs(int(round(float(subarray[-2]),0)))\n",
    "    #print factor\n",
    "    subarray = [subarray]*factor\n",
    "    df_array = np.vstack((df_array, subarray))\n",
    "    #print len(df_array)\n",
    "print len(df_array)\n",
    "\n",
    "output=pd.DataFrame(df_array[1:-1], columns=lines[0].split(' '))\n",
    "#output.to_hdf('R:/SoundCast/estimation/2014/hrecp2_expanded.h5','hrecp2_expanded',append=True)\n",
    "\n",
    "####################check data##############\n",
    "store = pd.HDFStore('R:/SoundCast/estimation/2014/survey14_expanded.h5')\n",
    "data1 = store['precp2_expanded']\n",
    "data2 = store['hrecp2_expanded']\n",
    "\n",
    "#####################reformat for DaySim#####################\n",
    "#for each column in obove files, create tables and save them in h5 files. \n",
    "col_to_save = ['hhno']\n",
    "data1[col_to_slct].to_hdf('R:/SoundCast/estimation/2014/test.h5', 'hhno', format='table', data_columns=['hhno'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person = pd.read_csv(r'R:\\SoundCast\\estimation\\2014\\expanded\\precp2_expanded.csv', sep=',')\n",
    "household = pd.read_csv(r'R:\\SoundCast\\estimation\\2014\\expanded\\hrecp2_expanded.csv', sep=',')\n",
    "household.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File('R:/SoundCast/estimation/2014/expanded/HH_test.h5', 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grp = f.create_group(\"Household\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in household.columns: \n",
    "    dset2 = grp.create_dataset(column, data=list(household[column]))\n",
    "    print dset2.name\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File('R:/SoundCast/estimation/2014/expanded/HH_test.h5', 'r+')\n",
    "anothergrp = f.create_group(\"Person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in person.columns: \n",
    "    dset3 = anothergrp.create_dataset(column, data=list(person[column]))\n",
    "    print dset3.name\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
