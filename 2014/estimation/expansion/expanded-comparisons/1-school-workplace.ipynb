{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notebooks are used to compare a base and scenario, from expanded surveys or model outputs, in H5 format. To run: from the menu bar above, choose **Cell -> Run All ** or run lines individually. Use the toggle button below to hide/show the raw Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ## School and Workplace Location Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summaries for Daysim Models 1.1 - 1.5*\n",
    "\n",
    "    - Workplace Location (1.1)\n",
    "        - by County\n",
    "        - by District\n",
    "    - School Location (1.2)\n",
    "        - by County\n",
    "        - by District\n",
    "    - Workers Paying to Park at Work (1.3)\n",
    "        - by Workplace County\n",
    "        - by Workplace District\n",
    "    - Transit Pass Ownership (1.4)\n",
    "       - by Workplace County \n",
    "       - by Workplace District\n",
    "       - by Home County \n",
    "       - by Home District\n",
    "    - Auto Ownership (1.5)\n",
    "       - by County\n",
    "       - by District\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"//code.highcharts.com/stock/highstock.js\"></script>\n",
       "<script src=\"//code.highcharts.com/highcharts-more.js\"></script>\n",
       "<script src=\"//code.highcharts.com/modules/exporting.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pylab as P\n",
    "from IPython.display import display, display_pretty, Javascript, HTML\n",
    "from pandas_highcharts.core import serialize\n",
    "from pandas_highcharts.display import display_charts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show charts in notebook\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define data sources\n",
    "\n",
    "# 2006 survey\n",
    "survey06_dir = r'R:\\SoundCast\\releases\\TransportationFutures2010\\scripts\\summarize'\n",
    "\n",
    "\n",
    "# 2014 survey\n",
    "survey14_dir = r'D:\\travel-studies\\2014\\estimation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read Model Scenario Results\n",
    "scen = h5py.File(survey06_dir + r'/survey.h5','r+')\n",
    "scen_name = '2006 Survey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read Base Data\n",
    "base_file = r'/survey14.h5'\n",
    "\n",
    "base = h5py.File(survey14_dir + base_file ,'r+')\n",
    "base_name = '2014 Survey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_df(h5file, h5table, var_dict, survey_file=False):\n",
    "    ''' Convert H5 into dataframe '''\n",
    "    data = {}\n",
    "    if survey_file:\n",
    "        # survey h5 have nested data structure, different than daysim_outputs\n",
    "        for col_name, var in var_dict.iteritems():\n",
    "            data[col_name] = [i[0] for i in h5file[h5table][var][:]]\n",
    "    else:\n",
    "        for col_name, var in var_dict.iteritems():\n",
    "            data[col_name] = [i for i in h5file[h5table][var][:]]\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base['Person']['pno'][:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tripdict={'Household ID': 'hhno',\n",
    "            'Person Number': 'pno',\n",
    "            'Travel Time':'travtime',\n",
    "            'Travel Cost': 'travcost',\n",
    "            'Travel Distance': 'travdist',\n",
    "            'Mode': 'mode',\n",
    "            'Purpose':'dpurp',\n",
    "            'Departure Time': 'deptm',\n",
    "            'Expansion Factor': 'trexpfac'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_scen = build_df(h5file=scen, h5table='Trip', var_dict=tripdict, survey_file=True)\n",
    "trip_base = build_df(h5file=base, h5table='Trip', var_dict=tripdict, survey_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persondict={'Household ID': 'hhno',\n",
    "            'Person Number': 'pno',\n",
    "            'Transit Pass': 'ptpass',\n",
    "            'Auto Time to Work': 'pwautime',\n",
    "            'Auto Distance to Work': 'pwaudist',\n",
    "            'Worker Type': 'pwtyp',\n",
    "            'Student Type': 'pstyp',\n",
    "            'Usual Commute Mode': 'puwmode',\n",
    "            'Workplace TAZ': 'pwtaz',\n",
    "            'School TAZ': 'pstaz',\n",
    "            'Age': 'pagey',\n",
    "            'Person Type': 'pptyp',\n",
    "            'Expansion Factor': 'psexpfac'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "person_scen = build_df(h5file=scen, h5table='Person', var_dict=persondict, survey_file=True)\n",
    "person_base = build_df(h5file=base, h5table='Person', var_dict=persondict, survey_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create unique ID for person by concatenating household ID and person number \n",
    "person_scen['personID'] = (person_scen['Household ID'].astype('str')+person_scen['Person Number'].astype('str')).astype('int')\n",
    "person_base['personID'] = (person_base['Household ID'].astype('str')+person_base['Person Number'].astype('str')).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hhdict={'Household ID': 'hhno',\n",
    "        'Household Size': 'hhsize',\n",
    "        'Household Vehicles': 'hhvehs',\n",
    "        'Household Workers': 'hhwkrs',\n",
    "        'Household Income': 'hhincome',\n",
    "        'Household TAZ': 'hhtaz',\n",
    "        'Expansion Factor': 'hhexpfac'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh_scen = build_df(h5file=scen, h5table='Household', var_dict=hhdict, survey_file=True)\n",
    "hh_base = build_df(h5file=base, h5table='Household', var_dict=hhdict, survey_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Full-time worker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c8928143eb6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mperson_base\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Worker Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mperson_base\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Worker Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mperson_scen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Worker Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mperson_scen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Worker Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Full-time worker'"
     ]
    }
   ],
   "source": [
    "# Add labels for worker type\n",
    "labels = {\n",
    "  0: \"Not a worker\",  \n",
    "  1: \"Full-time worker\",\n",
    "  2: \"Part-time worker\",\n",
    "}\n",
    "\n",
    "person_base['Worker Type'] = ([labels[x] for x in person_base['Worker Type']])\n",
    "person_scen['Worker Type'] = ([labels[x] for x in person_scen['Worker Type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join household records to person records\n",
    "hh_per_scen = pd.merge(left=person_scen, right=hh_scen,on='Household ID',suffixes=('_p','_h'))\n",
    "hh_per_base = pd.merge(left=person_base, right=hh_base,on='Household ID',suffixes=('_p','_h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File utils/taz_lookup.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-7a9f3a5b1f98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Join household geography\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtaz_geog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'utils/taz_lookup.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtaz_geog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhh_per_scen_home_geog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhh_per_scen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtaz_geog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Household TAZ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TAZ'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhh_per_base_home_geog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhh_per_base\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtaz_geog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Household TAZ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TAZ'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    463\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3163)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:5779)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File utils/taz_lookup.csv does not exist"
     ]
    }
   ],
   "source": [
    "# Join household geography\n",
    "taz_geog = pd.read_csv(r'utils/taz_lookup.csv')\n",
    "taz_geog.reindex\n",
    "hh_per_scen_home_geog = pd.merge(hh_per_scen, taz_geog, left_on='Household TAZ', right_on='TAZ')\n",
    "hh_per_base_home_geog = pd.merge(hh_per_base, taz_geog, left_on='Household TAZ', right_on='TAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join workplace geography\n",
    "hh_per_scen_work_geog = pd.merge(hh_per_scen, taz_geog, left_on='Workplace TAZ', right_on='TAZ')\n",
    "hh_per_base_work_geog = pd.merge(hh_per_base, taz_geog, left_on='Workplace TAZ', right_on='TAZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs by Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([hh_per_scen_work_geog.groupby('County').sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_work_geog.groupby('County').sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distribution\n",
    "df_new = pd.DataFrame([df[scen_name]/df[scen_name].sum(),\n",
    "             df[base_name]/df[base_name].sum()]).T\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_charts(df_new, kind='bar', title='Job Location Distribution by County')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Jobs by District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "district_col = 'New DistrictName'\n",
    "df = pd.DataFrame([hh_per_scen_work_geog.groupby(district_col).sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_work_geog.groupby(district_col).sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distribution\n",
    "df_new = pd.DataFrame([df[scen_name]/df[scen_name].sum(),\n",
    "             df[base_name]/df[base_name].sum()]).T\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_charts(df_new, kind='bar', title='Job Location Distribution by County')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Distribution of Worker Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distribution\n",
    "df_dist = pd.DataFrame([df[scen_name]/person_scen.count()['personID'],\n",
    "                   df[base_name]/person_base.count()['personID']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_charts(df_dist, kind='bar', title='Worker Type Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join school geography\n",
    "hh_per_scen_school_geog = pd.merge(hh_per_scen, taz_geog, left_on='School TAZ', right_on='TAZ')\n",
    "hh_per_base_school_geog = pd.merge(hh_per_base, taz_geog, left_on='School TAZ', right_on='TAZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([hh_per_scen_school_geog.groupby('County').sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_school_geog.groupby('County').sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame([df[scen_name]/df[scen_name].sum(),\n",
    "             df[base_name]/df[base_name].sum()]).T\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_charts(df_new, kind='bar', title='School Location Distribution by County')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### School Location by District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "district_col = 'New DistrictName'\n",
    "df = pd.DataFrame([hh_per_scen_school_geog.groupby(district_col).sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_school_geog.groupby(district_col).sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame([df[scen_name]/df[scen_name].sum(),\n",
    "             df[base_name]/df[base_name].sum()]).T\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_charts(df_new, kind='bar', title='School Location Distribution by District')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Transit Pass Ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Home Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([person_scen.groupby('Transit Pass').sum()['Expansion Factor'],\n",
    "              person_base.groupby('Transit Pass').sum()['Expansion Factor']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By Home County\n",
    "colname = 'Transit Pass'\n",
    "df = pd.DataFrame([hh_per_scen_home_geog.groupby(colname).sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_home_geog.groupby(colname).sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By Home District\n",
    "colname = 'New DistrictName'\n",
    "df = pd.DataFrame([hh_per_scen_home_geog.groupby(colname).sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_home_geog.groupby(colname).sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Work Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By Work County\n",
    "colname = 'County'\n",
    "df = pd.DataFrame([hh_per_scen_work_geog.groupby(colname).sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_work_geog.groupby(colname).sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By Work District\n",
    "colname = 'New DistrictName'\n",
    "df = pd.DataFrame([hh_per_scen_work_geog.groupby(colname).sum()['Expansion Factor_h'],\n",
    "                   hh_per_base_work_geog.groupby(colname).sum()['Expansion Factor_h']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_hh_scen = hh_scen[hh_scen.index>=0]\n",
    "df = pd.DataFrame([hh_scen.groupby('Household Vehicles').sum()['Expansion Factor'],\n",
    "                   hh_base.groupby('Household Vehicles').sum()['Expansion Factor']]).T\n",
    "df.columns=([scen_name,base_name])\n",
    "df=df[df.index>=0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame([df[scen_name]/df[scen_name].sum(),\n",
    "             df[base_name]/df[base_name].sum()]).T\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_charts(df_new, kind='bar', title='Auto Ownership Distribution Regionwide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average autos per household\n",
    "print scen_name + \": \" + str(sum(hh_scen['Household Vehicles']*hh_scen['Expansion Factor'])/sum(hh_scen['Expansion Factor']))\n",
    "print base_name + \": \" + str(sum(hh_base['Household Vehicles']*hh_base['Expansion Factor'])/sum(hh_base['Expansion Factor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Auto Ownership by Income\n",
    "# Create common income ranges\n",
    "def map_income(df, in_field, out_field):\n",
    "    \n",
    "    # Define categories\n",
    "    incmap = {}\n",
    "    for i in range(0, 20000):\n",
    "        incmap.update({i: ' <20k'})\n",
    "    for i in range(20000, 40000):\n",
    "        incmap.update({i: '20k-40k'})\n",
    "    for i in range(40000, 60000):\n",
    "        incmap.update({i: '40k-60k'})\n",
    "    for i in range(60000, 75000):\n",
    "        incmap.update({i: '60k-75k'})\n",
    "    for i in range(75000, 100000):\n",
    "        incmap.update({i: '75k-100k'})\n",
    "    for i in range(100000, 150000):\n",
    "        incmap.update({i: '100k-150k'})\n",
    "    for i in range(150000, int(df[in_field].max())+1):\n",
    "        incmap.update({i: '>150k'})\n",
    "\n",
    "    df[out_field] = df[in_field].map(incmap)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_scen = map_income(hh_scen, in_field='Household Income', out_field='Income')\n",
    "hh_base = map_income(hh_base, in_field='Household Income', out_field='Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh_base.groupby('Household Income').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_scen = pd.pivot_table(data=hh_scen, index='Household Vehicles', columns=['Income'], \n",
    "                    aggfunc='sum', values='Expansion Factor', fill_value=False, margins=False)\n",
    "df_base = pd.pivot_table(data=hh_base, index='Household Vehicles', columns=['Income'], \n",
    "                    aggfunc='sum', values='Expansion Factor', fill_value=False, margins=False)\n",
    "# Sort the columns\n",
    "df_scen = df_scen[[' <20k','20k-40k','40k-60k','60k-75k',\n",
    "                   '75k-100k','100k-150k','>150k']]\n",
    "df_base = df_base[[' <20k','20k-40k','40k-60k','60k-75k',\n",
    "                   '75k-100k','100k-150k','>150k']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate averages by income class\n",
    "df = pd.DataFrame([[sum(df_scen[colname]*df_scen.index)/sum(df_scen[colname]) for colname in df_scen.columns],\n",
    "                    [sum(df_base[colname]*df_base.index)/sum(df_base[colname]) for colname in df_base.columns]]).T\n",
    "df.index=df_base.columns\n",
    "df.columns=[scen_name,base_name]\n",
    "df['% difference 2006->2014']= (df[base_name]-df[scen_name])/df[scen_name]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh_per_scen_home_geog.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average ownership by district\n",
    "df_scen = pd.pivot_table(data=hh_per_scen_home_geog, index='Household Vehicles', columns=['New DistrictName'], \n",
    "                    aggfunc='sum', values='Expansion Factor_p', fill_value=False, margins=False)\n",
    "df_base = pd.pivot_table(data=hh_per_base_home_geog, index='Household Vehicles', columns=['New DistrictName'], \n",
    "                    aggfunc='sum', values='Expansion Factor_p', fill_value=False, margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate averages by district\n",
    "df = pd.DataFrame([[sum(df_scen[colname]*df_scen.index)/sum(df_scen[colname]) for colname in df_scen.columns],\n",
    "                    [sum(df_base[colname]*df_base.index)/sum(df_base[colname]) for colname in df_base.columns]]).T\n",
    "df.index=df_base.columns\n",
    "df.columns=[scen_name,base_name]\n",
    "df\n",
    "df['% difference 2006->2014']= (df[base_name]-df[scen_name])/df[scen_name]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average ownership by county\n",
    "df_scen = pd.pivot_table(data=hh_per_scen_home_geog, index='Household Vehicles', columns=['County'], \n",
    "                    aggfunc='sum', values='Expansion Factor_p', fill_value=False, margins=False)\n",
    "df_base = pd.pivot_table(data=hh_per_base_home_geog, index='Household Vehicles', columns=['County'], \n",
    "                    aggfunc='sum', values='Expansion Factor_p', fill_value=False, margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate averages by county\n",
    "df = pd.DataFrame([[sum(df_scen[colname]*df_scen.index)/sum(df_scen[colname]) for colname in df_scen.columns],\n",
    "                    [sum(df_base[colname]*df_base.index)/sum(df_base[colname]) for colname in df_base.columns]]).T\n",
    "df.index=df_base.columns\n",
    "df.columns=[scen_name,base_name]\n",
    "df\n",
    "df['% difference 2006->2014']= (df[base_name]-df[scen_name])/df[scen_name]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
