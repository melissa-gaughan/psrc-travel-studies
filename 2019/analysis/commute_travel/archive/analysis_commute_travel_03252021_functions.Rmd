---
title: "Statistical Analysis Functions"
subtitle: "Example: comparing commuting patterns by gender and race"
author: "Suzanne Childress & Mary Richards"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_depth: 6
    toc_float: true
  word_document: default
  pdf_document: default
---

This document includes functions that help with statistical analysis, more specifically comparing the differences between groups to determine if they are statistically significant. These functions will be applied to the Household Travel Survey (2019) to compare commuting patterns by gender and race. 

```{r global-options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE) # formatting
```

```{r libraries, include=FALSE}
# source('travel_survey_analysis_functions.R')
library(tidyverse)
library(openxlsx)
library(odbc)
library(DBI)
library(ggplot2)

library(table1)
library(knitr)
library(kableExtra)
library(summarytools)
library(formattable)
library(ggpubr) #boxplots
library(car) #Levene's test
library(broom) #anova, p-values
```

```{r functions, include=FALSE}
# connecting to Elmer
db.connect <- function() {
  elmer_connection <- dbConnect(odbc(),
                                driver = "SQL Server",
                                server = "AWS-PROD-SQL\\Sockeye",
                                database = "Elmer",
                                trusted_connection = "yes"
  )
}

# a function to read tables and queries from Elmer
read.dt <- function(astring, type =c('table_name', 'sqlquery')) {
  elmer_connection <- db.connect()
  if (type == 'table_name') {
    dtelm <- dbReadTable(elmer_connection, SQL(astring))
  } else {
    dtelm <- dbGetQuery(elmer_connection, SQL(astring))
  }
  dbDisconnect(elmer_connection)
  dtelm
}

# # Create a simplified crosstab from one variable, calculate counts, totals, shares, and MOE for categorical data
# create_table_one_var_simp= function(var1, table_temp, table_type) {
#   #table_temp = recategorize_var_upd(var2,table_temp)
#   #print(table_temp)
#   if (table_type == "household" | table_type == "person" ) {
#     weight_2017 = "hh_wt_revised"
#     weight_2019 = "hh_wt_2019"
#     weight_comb = "hh_wt_combined"
#   } else if (table_type == "trip") {
#     weight_2017 = "trip_weight_revised"
#     weight_2019 = "trip_wt_2019"
#     weight_comb = "trip_wt_combined"  
#   } 
#   
#   temp = table_temp %>% 
#     dplyr::select(!!sym(var1), all_of(weight_2019)) %>% 
#     filter(!.[[1]] %in% missing_codes, !is.na(.[[1]])) %>% 
#     group_by(!!sym(var1)) %>% 
#     summarise(SampleSize=n(),
#               Weighted_2019 = sum(.data[[weight_2019]],na.rm = TRUE), 
#               Weighted_2019 = round(Weighted_2019, 0)) %>% 
#     mutate(WeightedPercent = Weighted_2019/sum(Weighted_2019)*100, 
#            WeightedPercent = round(WeightedPercent, 2)) %>% 
#     ungroup() %>%  
#     mutate(MOE=1.65*(0.25/sum(SampleSize))^(1/2)*100, 
#            MOE=round(MOE, 2)) %>% 
#     arrange(var1)
#   return(temp)
# }

# # Create a crosstab from two variables, calculate counts, totals, and shares for categorical data
# cross_tab_categorical <- function(table, var1, var2, wt_field) {
#   expanded <- table %>% 
#     group_by(.data[[var1]],.data[[var2]]) %>%
#     dplyr::summarize(Count= n(),Total=sum(.data[[wt_field]])) %>%
#     group_by(.data[[var1]])%>%
#     mutate(Percentage=Total/sum(Total)*100)
#   
#   
#   expanded_pivot <-expanded%>%
#     pivot_wider(names_from=.data[[var2]], values_from=c(Percentage,Total, Count))
#   
#   return (expanded_pivot)
#   
# } 

# # Create margins of error for dataset
# categorical_moe <- function(sample_size_group){
#   sample_w_MOE<-sample_size_group %>%
#     mutate(p_col=p_MOE) %>%
#     mutate(MOE_calc1= (p_col*(1-p_col))/sample_size) %>%
#     mutate(MOE_Percent=z*sqrt(MOE_calc1)*100)
#   
#   sample_w_MOE<- dplyr::select(sample_w_MOE, -c(p_col, MOE_calc1))
#   
#   return(sample_w_MOE)
# }

# # create table with bivariate analysis stats
# bivariate_Pvalue <- function(outcome, explanatory){
#   model_output <- polr(as.factor(outcome) ~ explanatory, Hess=T)
#   ctable <- coef(summary(model_output))
#   # calculate and store p values
#   p <- pnorm(abs(ctable[,"t value"]), lower.tail = F)*2
#   p_round <- round(pnorm(abs(ctable[,"t value"]), lower.tail = F)*2,4)
#   #odds ratio
#   oddsratio <- round(exp(coef(model_output)),4)
#   #combine elements
#   ctable <- cbind(round(ctable,4), "p-value"=p, "simp p."=p_round, "odds ratio"=oddsratio)
#   return(ctable)
# }

# # create stargazer table
# stargazer_table <- function(outcome, explanatory, table_title){
#   stargazer::stargazer(
#     polr(as.factor(outcome) ~ explanatory, Hess=T), type = "html",
#                       title =  table_title,
#                       notes.append =  FALSE, 
#                       notes =  c("<sup>&sstarf;</sup>p<0.1; <sup>&sstarf;&sstarf;</sup>p<0.05; <sup>&sstarf;&sstarf;&sstarf;</sup>p<0.01"))
# 
# }

# Confidence Interval for mean = sample mean + Z-value for confidence level(sample st. dev/sqrt(number of elements in sample))
Mean.SD_CI <- function(x, cat_var, num_var, weight_var){
  cat_var <- enquo(cat_var)
  num_var <- enquo(num_var)
  weight_var <- enquo(weight_var)

  Mean.SD_CI_table <- x %>%
    group_by(!!cat_var) %>%
    summarize(Group_weight = round(sum(!!weight_var),0),
              Weighted_percent = (round(Group_weight/sum(x$hh_wt_2019),4)),
              Weighted_avg = round(weighted.mean(!!num_var, !!weight_var),2),
              sd = round(sd(!!num_var),2),
              se = round(sd/sqrt(n()),2),
              CI_90 = round(z*(sd/sqrt(n())),2),
              CI_95 = round(z_95*(sd/sqrt(n())),2),
              n=n())
    
  Mean.SD_CI_temp<- dplyr::select(Mean.SD_CI_table, -c(n))
  
  # return(Mean.SD_CI_temp)
  return(Mean.SD_CI_table)
}

# adding commas to numbers - thousand separator 
mycomma <- function(digits = 0) {
      formatter("span", x ~ comma(x, digits = digits)
      )
    }

# # rounding function applied to categorical columns 
# my.render.cat <- function(x) {
#     c("", sapply(stats.default(x), function(y) with(y,
#         sprintf("%d (%.0f%%)", FREQ, PCT))))}

# Statistical assumptions for margins of error
p_MOE <- 0.5
z <- 1.645 #90% CI
z_95 <- 1.96 #95% CI
# missing_codes <- c('Missing: Technical Error', 'Missing: Non-response', 
#                    'Missing: Skip logic', 'Children or missing', 'Prefer not to answer',
#                    'Missing')
```

```{r read in and set up data}
#### Read in Data ####
#where you are running your R code
wrkdir <- "C:/Users/mrichards/Documents/GitHub/travel-studies/2019/analysis"


#where you want to output tables
file_loc <- 'C:/Users/mrichards/Documents/GitHub/travel-studies/2019/analysis/commute_travel/outputs'

sql.trip.query <- paste("SELECT hhincome_detailed, race_category, person_dim_id, mode_simple,
                        survey_year, o_purpose, d_purpose, trip_wt_2019 
                        FROM HHSurvey.v_trips_2017_2019")

trips <- read.dt(sql.trip.query, 'sqlquery')
trips_2019 <- trips %>% filter(survey_year==2019)

sql.person.query <- paste("SELECT employment, hhincome_detailed, hhincome_broad, race_category, person_dim_id, gender, age, age_category, education, vehicle_count,commute_auto_time,commute_auto_Distance, mode_freq_1,  mode_freq_2,  mode_freq_3, mode_freq_4, mode_freq_5, workplace, survey_year, sample_county, work_county,telecommute_freq, hh_wt_2019 FROM HHSurvey.v_persons_2017_2019")

persons<-read.dt(sql.person.query, 'sqlquery')
persons_2019 <- persons  %>% filter(survey_year==2019)
```
\

## Background Information
### Commuting Trips
This analysis will focus on the commute trips of people who usually work outside the home. 

Commuting will be defined as the trips where one of the trip ends is a regular workplace - based on the survey logic, the origin or destination purpose is 'Went to primary workplace'

### Commuters
For this analysis, commuters are those with: 

1. full-time or part-time paid employment or those who identified as self-employed with workplaces.  
2. workplaces that are not at home  
3. commute distances less than 200 miles
\
\

```{r}
workers <- persons_2019 %>% 
  filter(employment=='Employed full time (35+ hours/week, paid)'|
           employment=='Employed part time (fewer than 35 hours/week, paid)'|
           employment=='Self-employed')

# get workers who don't work at home all the time with commute distances less than 200 miles
# remove outliers
not_home_workers <- workers %>% 
  filter(workplace!='At home (telecommute or self-employed with home office)') %>%
  filter(commute_auto_Distance<200)
```
\
\

## Research: Individual Variables
Commute distance will be the dependent variable in this analysis and the two independent variables will be gender and race. 

### 1. Commute distance
```{r}
mean_dist<-weighted.mean(not_home_workers$commute_auto_Distance,
                         w=not_home_workers$hh_wt_2019,na.rm=TRUE)

ggplot(not_home_workers, aes(x=commute_auto_Distance, weight=hh_wt_2019)) + 
  geom_histogram(fill="#00A7A0", binwidth=2)+xlim(c(0, 50)) +
  geom_vline(xintercept=mean_dist) +
  labs(title="Distribution of 2019 Commute Distances (from the HTS)",
      x ="Commute Distance (miles)", y = "Number of Workers (Region)")
```
\
\

### 2. Race
```{r}
# reorder race categories
not_home_workers$race_category <- 
  factor(not_home_workers$race_category,
         levels=c("African American",
                  "Asian",
                  "Hispanic",
                  "White Only",
                  "Other",
                  "Missing"))
```
People who identify as White Only have the farthest commutes (15 miles). The margins of error for African American and Hispanic groups are relatively large due to the small sample sizes. 
\

*The average commuting distance by race*
```{r dist race with sample CI}
dist_race_stats <- Mean.SD_CI(not_home_workers, race_category, commute_auto_Distance, hh_wt_2019)

formattable(dist_race_stats,
            list(area(col=c(2,9))~mycomma(digits=0),
                 Weighted_percent=percent),
            align=c("l", rep("c", NCOL(dist_race_stats))),
            col.names=c("Race", "2019 Estimate", "2019 Percent", "2019 Average", "SD", "SE", "CI 90%", "CI 95%", "Sample Size"))
```

```{r}
avg_dist_by_race<-not_home_workers %>%
  group_by(race_category) %>% 
  summarize(n=n(),
            Percent=round((n/nrow(not_home_workers))*100,2),
            HouseholdWeight=sum(hh_wt_2019),
            avg_weighted_dist=round(weighted.mean(commute_auto_Distance,hh_wt_2019),2))

ggplot(avg_dist_by_race, aes(x=race_category, y=avg_weighted_dist)) + 
  geom_col() +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="Average Auto Commute Distance by Race",
      x ="Race Categories", y = "Average Weighted Distance (miles)") +
  geom_errorbar(aes(ymin=dist_race_stats$Weighted_avg-dist_race_stats$CI_95, 
                    ymax=dist_race_stats$Weighted_avg+dist_race_stats$CI_95), 
                width=.2,
                position=position_dodge(.9))
```
\
\

#### Aggregated Race
Because of small sample sizes, some of the respondents have been aggregated.
\
\

<span style="color:#486CAB">**African American, Hispanic, and Other**</span>  
For this analysis, respondents who identified as African American, Hispanic, and Other were aggregated. 
```{r}
# reorder race categories
not_home_workers$race_category <- as.character(not_home_workers$race_category)
not_home_workers <- not_home_workers %>%
  mutate(race_agg_2 = case_when(race_category=="African American" |
                                  race_category=="Hispanic" |
                                  race_category=="Other" ~ "Other POC",
                                race_category=="Asian" ~ "Asian POC",
                                TRUE~.$race_category))

not_home_workers$race_agg_2 <- factor(not_home_workers$race_agg_2,
                                      levels=c("Asian POC",
                                               "Other POC",
                                               "White Only",
                                               "Missing"))
```
People who identify as African American, Hispanic, or Other have shorter commutes (11 miles), while White Only individuals have longer commutes (15 minutes).

The margin of error for the Other POC group is distinct from respondents identifying as Asian or White Only.
\
\

*The average commuting distance by race*
```{r dist race_2 with sample CI}
dist_race_stats <- Mean.SD_CI(not_home_workers, race_agg_2, commute_auto_Distance, hh_wt_2019)

formattable(dist_race_stats,
            list(area(col=c(2,9))~mycomma(digits=0),
                 Weighted_percent=percent),
            align=c("l", rep("c", NCOL(dist_race_stats))),
            col.names=c("Race", "2019 Estimate", "2019 Percent", "2019 Average", "SD", "SE", "CI 90%", "CI 95%", "Sample Size"))
```

```{r}
avg_dist_by_race<-not_home_workers %>%
  group_by(race_agg_2) %>% 
  summarize(n=n(),
            Percent=round((n/nrow(not_home_workers))*100,2),
            HouseholdWeight=sum(hh_wt_2019),
            avg_weighted_dist=round(weighted.mean(commute_auto_Distance,hh_wt_2019),2))

ggplot(avg_dist_by_race, aes(x=race_agg_2, y=avg_weighted_dist)) + 
  geom_col() +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="Average Auto Commute Distance by Race",
      x ="Race Categories", y = "Average Weighted Distance (miles)") +
  geom_errorbar(aes(ymin=dist_race_stats$Weighted_avg-dist_race_stats$CI_95, 
                    ymax=dist_race_stats$Weighted_avg+dist_race_stats$CI_95), 
                width=.2,
                position=position_dodge(.9))
```
\
\


### 3. Gender
```{r}
# reorder gender categories
not_home_workers$gender <-
  factor(not_home_workers$gender,
         levels=c("Female",
                  "Male",
                  "Another",
                  "Prefer not to answer"))
```
People who identify as male have the farthest commute (15 miles). Females have shorter commutes (13 miles), and people of another gender or who prefer not to answer do not have enough samples to draw a statistical conclusion. 
\

*The average commuting distance by gender*
```{r dist gender with sample CI}
dist_gender_stats <- Mean.SD_CI(not_home_workers, gender, commute_auto_Distance, hh_wt_2019)

formattable(dist_gender_stats,
            list(area(col=c(2,9))~mycomma(digits=0),
                 Weighted_percent=percent),
            align=c("l", rep("c", NCOL(dist_gender_stats))),
            col.names=c("Gender", "2019 Estimate", "2019 Percent", "2019 Average", "SD", "SE", "CI 90%", "CI 95%", "Sample Size"))
```
\

Because of the small sample sizes for respondents identifying as Another or choosing not to answer, these respondents were removed from the graph:
\
\
```{r}
avg_dist_by_gender<-not_home_workers %>%
  select(gender, commute_auto_Distance, hh_wt_2019) %>%
  group_by(gender)

temp <- avg_dist_by_gender %>%
  filter(gender=="Female" | gender=="Male") %>%
  summarize(n=n(),
            Percent=round((n/nrow(avg_dist_by_gender))*100,2),
            Group_weight = round(sum(hh_wt_2019),0),
            Weighted_percent = (round(Group_weight/sum(avg_dist_by_gender$hh_wt_2019),4)*100),
            Weighted_avg = round(weighted.mean(commute_auto_Distance, hh_wt_2019),2),
            sd = round(sd(commute_auto_Distance),3),
            se = round(sd/sqrt(n),3),
            CI_90 = round(z*(sd/sqrt(n)),3),
            CI_95 = round(z_95*(sd/sqrt(n)),3))

ggplot(temp, aes(x=gender, y=Weighted_avg)) + 
  geom_col() +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="Average Auto Commute Distance by Gender",
       x ="Gender Categories", 
       y = "Average Weighted Distance (miles)") +
  geom_errorbar(aes(ymin=Weighted_avg-CI_95, 
                    ymax=Weighted_avg+CI_95), 
                width=.2,
                position=position_dodge(.9))
```

```{r, include=FALSE, eval=FALSE}
avg_dist_by_gender<-not_home_workers %>%
  group_by(gender) %>% 
  summarize(n=n(),
            Percent=round((n/nrow(not_home_workers))*100,2),
            HouseholdWeight=sum(hh_wt_2019),
            avg_weighted_dist=round(weighted.mean(commute_auto_Distance,hh_wt_2019),2))

ggplot(avg_dist_by_gender, aes(x=gender, y=avg_weighted_dist)) + 
  geom_col() +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="Average Auto Commute Distance by Gender",
      x ="Gender Categories", y = "Average Weighted Distance (miles)") +
  geom_errorbar(aes(ymin=dist_gender_stats$Weighted_avg-dist_gender_stats$CI_95, 
                    ymax=dist_gender_stats$Weighted_avg+dist_gender_stats$CI_95), 
                width=.2,
                position=position_dodge(.9))
```
\
\


## Research: Multiple Variables

### <span style="color:#8CC63E">Visually comparing the differences</span>
```{r}
# commute distance: gender and race
not_home_workers$race_category <- factor(not_home_workers$race_category,
                                         levels = c("African American",
                                                    "Asian",
                                                    "Hispanic",
                                                    "White Only",
                                                    "Other",
                                                    "Missing"))

avg_dist_by_gender_race<-not_home_workers %>%
  select(gender, race_category, race_agg_2, commute_auto_Distance, hh_wt_2019) %>%
  group_by(gender, race_category, race_agg_2)
```

```{r}
temp_gender_race <- avg_dist_by_gender_race %>%
  filter(gender=="Female" | gender=="Male") %>%
  group_by(gender, race_category) %>%
  summarize(n=n(),
            Percent=round((n/nrow(avg_dist_by_gender_race))*100,2),
            Group_weight = round(sum(hh_wt_2019),0),
            Weighted_percent = (round(Group_weight/sum(avg_dist_by_gender_race$hh_wt_2019),4)*100),
            Weighted_avg = round(weighted.mean(commute_auto_Distance, hh_wt_2019),2),
            sd = round(sd(commute_auto_Distance),3),
            se = round(sd/sqrt(n),3),
            CI_90 = round(z*(sd/sqrt(n)),3),
            CI_95 = round(z_95*(sd/sqrt(n)),3))

# plot with race along x-axis
ggplot(temp_gender_race, aes(x=race_category, y=Weighted_avg, fill=gender)) + 
  geom_bar(position="dodge", stat="identity") +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="Average Auto Commute Distance by Race",
       x ="Race Categories", 
       y = "Average Commute Distance (miles)",
       fill = "Gender") +
  geom_errorbar(aes(ymin=Weighted_avg-CI_95, 
                    ymax=Weighted_avg+CI_95), 
                width=.2,
                position=position_dodge(.9))

# plot with gender along x-axis
ggplot(temp_gender_race, aes(x=gender, y=Weighted_avg, fill=race_category)) + 
  geom_bar(position="dodge", stat="identity") +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="Average Auto Commute Distance by Gender",
       x ="Gender", 
       y = "Average Commute Distance (miles)",
       fill = "Race Categories") +
  geom_errorbar(aes(ymin=Weighted_avg-CI_95, 
                    ymax=Weighted_avg+CI_95), 
                width=.2,
                position=position_dodge(.9))
```
\
\
\

### <span style="color:#8CC63E">Statistically comparing the differences</span>
The following section provides a workflow to test if group means are statistically different. In this example, the independent variables, or the ways in which respondents will be grouped is by their identified gender and race. The dependent variable is commute distance by automobile  [(reference)](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/09%3A_Two-Sample_Problems/9.01%3A_Comparison_of_Two_Population_Means-_Large_Independent_Samples).
\

#### I. [**Two-Way ANOVA test in R**](http://www.sthda.com/english/wiki/two-way-anova-test-in-r)    
An ANOVA (Analysis of Variance) test is used to evaluate the effect of two grouping variables (or factors) on a response variable.
\
\

```{r}
# set up data frame with independent and dependent variables of interest
race_gender_test <- not_home_workers %>%
  dplyr::filter(gender=="Female" | gender=="Male") %>%
  dplyr::select(gender, race_category, commute_auto_Distance)
```

```{r}
# run two-way ANOVA test function
anova.test <- function(df_name, dependent, var1, var2) {
  # defining the objects
  dependent <- df_name[dependent]
  variable1 <- df_name[var1]
  variable2 <- df_name[var2]
  df <- data.frame(dependent=unlist(dependent),
                   variable1=unlist(variable1),
                   variable2=unlist(variable2))
  
  # generating ANOVA statistics
  ANOVA.output <<- aov(dependent~variable1+variable2, data=df)
  ANOVA_summary <- summary(ANOVA.output)
  # return(ANOVA_summary)
  
  # convert output summary into data.frame to get p-values
  summaries <<- df %>%
    do(tidy(aov(dependent~variable1+variable2, data=df)))
  # return(summaries)
  
  # generate message about next steps
  for(i in 1:(nrow(summaries)-1)){
    if(summaries[i,6] < 0.05){
      print(paste0("The p-value for ",summaries[i,1], " is statistically significant (p<0.05) and should be tested further using the Tukey HSD."))
      } else if (summaries[i,6] < 0.10){
        print(paste0("The p-value for ", summaries[i,1], " is statistically significant (p<0.10) and could be tested further using the Tukey HSD."))
        } else if (summaries[i,6] > 0.1){
        print(paste0("The p-value for ",summaries[i,1], " is not statistically significant and does not require further analysis."))
        } else {NULL}
    }
  }
```

```{r}
# use function with inputs
anova.gender.race <- anova.test(race_gender_test,
                                "commute_auto_Distance", 
                                "gender", 
                                "race_category")
```
\

##### Tukey HSD   
The Tukey HSD (Honest Significant Differences) performs multiple pairwise-comparisons between the means of groups. The gender variable doesn't need to be tested because it only has two levels, which have already been proven to be significantly different by ANOVA test. Therefore, the Tukey HSD test will be done only for the race variable.
```{r}
# TukeyHSD results
  for(i in 1:(nrow(summaries)-1)){
    if(summaries[i,6] < 0.10){
      Tukey_test <- TukeyHSD(ANOVA.output, which=paste0("variable",i))
      sig_test <- as.data.frame(tidy(Tukey_test)) %>%
        filter(adj.p.value < 0.10)
      print(paste0("The Tukey Test results for ", sig_test$term[1]))
      print(Tukey_test)
      print(paste0("Based on the output, the difference between '", sig_test$contrast[1], "' is significant."))
      } else if (summaries[i,6] >= 0.1){
        print(paste0("The p-value for ",sig_test$contrast, " is not statistically significant and does not require further analysis."))
    } else {NULL}
  }
```

```{r, workspace, include=FALSE, eval=FALSE}
res.aov2 <- aov(commute_auto_Distance ~ gender + race_category, data = race_gender_test)
summary(aov(commute_auto_Distance ~ gender + race_category, data = race_gender_test))
summary <- summary(res.aov2)
summary(res.aov2)[[1]][1,5] #extract p-value from first row
summary(res.aov2)[[1]][2,5] #extract p-value from second row

# convert output summary into data.frame to get p-values
summaries <- race_gender_test %>%
  do(tidy(aov(commute_auto_Distance ~ gender + race_category, data = .)))

# trying to automate previous step
p.value_fx <- function(df_name, dependent, var1, var2){
  summaries <- df_name %>%
    do(tidy(aov(dependent~var1+var2, data = .)))
  return(summaries)}

p.values_output <- p.value_fx(race_gender_test,
                              commute_auto_Distance, 
                              gender, race_category)

for(i in 1:(nrow(summaries)-1)){
  if(summaries[i,6] < 0.05){
    print("The p-value is statistically significant (p<0.05) and should be tested further using the Tukey HSD")
    } else if (summaries[i,6] < 0.15){
      print("The p-value is statistically significant (p<0.10) and could be tested further using the Tukey HSD")
      } else if (summaries[i,6] > 0.1){
        print("The p-value is not statistically significant")
        } else {
          NULL
        }
  }

```

```{r, include=FALSE, eval=FALSE}
Tukey_test <- TukeyHSD(ANOVA.output, which="variable2")
Tukey_test$variable2
result<-data.frame(Tukey_test$variable2)
result<-data.frame(Tukey_test$paste0("variable",2))

p_val <- result["p.adj"]


sig_test <- as.data.frame(tidy(Tukey_test)) %>% 
    filter(adj.p.value <.05)
sig_test$term[1]
print(sig_test$term)
sig_test <- as.data.frame(tidy(Tukey_test)) %>%
          filter(adj.p.value ==(0.05:0.10))


for(i in 1:(nrow(p_val)-1)){
  if(p_val[i,1] < 0.05){
    print(paste0("The difference between:",Tukey_test$variable2[i],"is statistically significant (p<0.05)"))
    } else if(p_val[i,1] < 0.10){
      print(paste0("The difference between:",p_val[i,0],"is statistically significant (p<0.10)"))
    } else {NULL}
  }

```
\
\

##### Check ANOVA assumptions: test validity   
Although the ANOVA test reveals significance, it is important to test the two of the main assumptions: homogeneity of variances (homoscedasticity) and normality.
\

1. Homogeneity of variances (Levene's test)
```{r, include=FALSE, eval=FALSE}
# to test homogeneity of variances
levene_race_gender <- leveneTest(commute_auto_Distance ~ gender*race_category, data=race_gender_test)
levene.pvalue <- as.data.frame(levene.output$`Pr(>F)`)
nrow(levene.pvalue)
levene.pvalue[1,1]
```

```{r}
# to test homogeneity of variances
levene.check <- function(df_name, dependent, var1, var2){
  # defining the objects
  dependent <- df_name[dependent]
  variable1 <- df_name[var1]
  variable2 <- df_name[var2]
  df <- data.frame(dependent=unlist(dependent),
                   variable1=unlist(variable1),
                   variable2=unlist(variable2))
  
  # generating statistic
  levene.output <<- leveneTest(dependent~variable1*variable2, data=df)
  levene.pvalue <- as.data.frame(levene.output$`Pr(>F)`)
  
  # results
  for(i in 1:(nrow(levene.pvalue)-1)){
    if(levene.pvalue[1,1]< 0.05){
      print(paste0("The p-value is statistically significant (p<0.05), which means that the variance among the  groups is significantly different (not equal) - Levene’s test rejected the null hypothesis of equal variances."))
      } else if (levene.pvalue[1,1]>= 0.05){
        print(paste0("The p-value is not statistically significant, which means that the variance among the groups is equal."))
        } else {NULL}
    }
  }
```

```{r}
# use function with inputs
levene.check(race_gender_test, "commute_auto_Distance", "gender", "race_category")
```
\
\

2. Normally distributed (Shapiro-Wilk test)  
```{r, include=FALSE, eval=FALSE}
# extract the residuals using output from ANOVA, run Shapiro-Wilk test
anova_residuals <- residuals(object=ANOVA.output)
# run Shapiro-Wilk test
shapiro.test(x=anova_residuals)

shapiro.wilk.check <- shapiro.test(x=residuals(object=ANOVA.output))
shapiro.wilk.check
shapiro.pvalue <- shapiro.wilk.check$p.value
nrow(shapiro.pvalue)

if(shapiro.pvalue< 0.05){
      print(paste0("The p-value is statistically significant (p<0.05), which means that the data are not normally distributed - the null hypothesis that the data are normally distributed is rejected."))
      } else if (shapiro.pvalue>= 0.05){
        print(paste0("The p-value is not statistically significant, which means that there is a normal distribution."))
        } else {NULL}
```

```{r}
shapiro.wilk.check <- function(){
  # extract the residuals using output from ANOVA
  anova_residuals <- residuals(object=ANOVA.output)
  # run Shapiro-Wilk test
  test <- shapiro.test(x=anova_residuals)
  shapiro.pvalue <- test$p.value
  
  # results
  if(shapiro.pvalue< 0.05){
    print(paste0("The p-value is statistically significant (p<0.05), which means that the data are not normally distributed - the null hypothesis that the data are normally distributed is rejected."))
    } else if (shapiro.pvalue>= 0.05){
      print(paste0("The p-value is not statistically significant, which means that there is a normal distribution."))
      } else {NULL}
  }
```

```{r}
# use function, doesn't require input variables because it references the output from the ANOVA test
shapiro.wilk.check()
```
\
\
\

#### II. [**Unpaired Two-Samples T-test in R**](http://www.sthda.com/english/wiki/wiki.php?id_contents=7600)    

Overall Process:  

1. F-test to test for differences in variances of **two** groups - 
    + if there is no significant difference, the classic t-test can be used
    + if the variances of the two groups of samples, being compared, are different (have unequal variances), the Welch t-test should be used. 
2. T-test or Welch t-test to compare the means of **two** unrelated groups of samples
\
\

Because the commute distances were difference between 'White Only-Asian' groups are statistically different these groups are further analyzed to see if the differences are significant between female- and male- identifying individuals.

<span style="color:#F05A28">*White Only*</span>

1. F-test
```{r, include=FALSE, eval=FALSE}
# test variance
white_vartest <- var.test(commute_auto_Distance~gender,
                          data=comp_gender_white)

white_vartest$p.value
```

```{r}
# set up data frame with independent and dependent variables of interest
comp_gender_white <- not_home_workers %>%
  # establish grouping variable that results in 2 levels
  dplyr::filter(gender=="Female" | gender=="Male") %>%
  dplyr::filter(race_category=="White Only") %>% 
  dplyr::select(gender, race_category, commute_auto_Distance)
```

```{r, include=FALSE, eval=FALSE}
comp_gender_allrace <- not_home_workers %>%
  # filter grouping variable in 2 levels
  filter(gender=="Female" | gender=="Male") %>%
  select(gender, race_category, commute_auto_Distance)

df_name <- not_home_workers
# dependent <- df_name$commute_auto_Distance
# var1 <- df_name$gender
# var2 <- df_name$race_category
var1.criteria <- "Female"
var2.criteria <- "Male"
variable1name <- "gender"
variable2name <- "race_category"
dependentname <- "commute_auto_Distance"

dependent <- df_name[dependentname]
variable1 <- df_name[variable1name]
variable2 <- df_name[variable2name]
df <- as.data.frame(cbind(variable1, variable2, dependent))


# df <- data.frame(dependent=unlist(dependent),
#                  variable1=unlist(variable1),
#                  variable2=unlist(variable2))



race_cat <- unique(variable2)
# race_cat[,1]
# data.frame output

for (i in 1:nrow(race_cat)){
  variable2 <- race_cat[i,1]
  print(paste0("They are ",paste0('"', variable2,'"')))
  var <- (paste0('"',variable2,'"'))
  cat(var)
  print(race_cat[i,1])
}

temp_table <- df %>%
  filter(.[1]==var1.criteria | .[1]==var2.criteria)

temp_table <- df %>%
  filter(.[1]==var1.criteria | .[1]==var2.criteria) %>%
  filter(.[2]=="African American")

for (i in 1:nrow(race_cat)){
  variable2_cat <- race_cat[i,1]
  var <- (paste0('"',variable2_cat,'"'))
  race_var <- cat(var)
  temp_table_2 <- df %>%
    filter(.[1]==var1.criteria | .[1]==var2.criteria) %>%
    filter(.[2]==race_var)}


for (i in seq(race_cat)){
  assign(paste0("Race Category: ",i), filter(temp_table, !!sym(race_cat[[i]])))
  }
    

for(i in 1:(nrow(summaries)-1)){
    if(summaries[i,6] < 0.10){
      Tukey_test <- TukeyHSD(ANOVA.output, which=paste0("variable",i))
      sig_test <- as.data.frame(tidy(Tukey_test)) %>%
        filter(adj.p.value < 0.10)
      print(paste0("The Tukey Test results for ", sig_test$term[1]))
      print(Tukey_test)
      print(paste0("Based on the output, the difference between '", sig_test$contrast[1], "' is significant."))
      } else if (summaries[i,6] >= 0.1){
        print(paste0("The p-value for ",sig_test$contrast, " is not statistically significant and does not require further analysis."))
    } else {NULL}
  }

    

F.test.check.1 <- function(df_name, dependent, var1, var2){
  # defining the objects
  dependent <- df_name[dependent]
  variable1 <- df_name[var1]
  variable2 <- df_name[var2]
  df <- data.frame(dependent=unlist(dependent),
                   variable1=unlist(variable1),
                   variable2=unlist(variable2))
  
  # generating statistic
  Fstats <- var.test(dependent~variable1, data=df)
  F.pvalue <- Fstats$p.value
  
  # generate message about next steps
  if(F.pvalue< 0.05){
    print(paste0("The p-value is statistically significant (p<0.05), which means that there is a significant difference between the variances of the two sets of data. This means that we cannot use the classic t-test (which assumes equality of the two variances) and must instead use the Welch t-test (which is an adaptated t-test, used when the two samples have unequal variances)."))
    } else if (F.pvalue>= 0.05){
      print(paste0("The p-value is not statistically significant, which means that the classic t-test can be used."))
    } else {NULL}
}

F.test.check.1(comp_gender_allrace, "commute_auto_Distance", "gender", "race_category")
```

```{r}
F.test.check <- function(df_name, dependent, var1){
  # defining the objects
  dependent <- df_name[dependent]
  variable1 <- df_name[var1]
  df <- data.frame(dependent=unlist(dependent),
                   variable1=unlist(variable1))
  
  # generating statistic
  Fstats <- var.test(dependent~variable1, data=df)
  print(Fstats)
  F.pvalue <- Fstats$p.value
  
  # generate message about next steps
  if(F.pvalue< 0.05){
    print(paste0("The p-value is statistically significant (p<0.05), which means that there is a significant difference between the variances of the two sets of data. This means that we cannot use the classic t-test (which assumes equality of the two variances) and must instead use the Welch t-test (which is an adaptated t-test, used when the two samples have unequal variances)."))
    } else if (F.pvalue>= 0.05){
      print(paste0("The p-value is not statistically significant, which means that there is no significant differene between the variances of the two sets of data. This means that we can apply the classic t-test to compare the means of the different groups."))
    } else {NULL}
  }
```

```{r}
# use function with inputs
F.test.check(comp_gender_white, "commute_auto_Distance", "gender")
```
\

2. Welch t-test
```{r, include=FALSE, eval=FALSE}
Welch_gender_white <- t.test(commute_auto_Distance~gender,
       data=comp_gender_white)
Welch_gender_white
Welch_gender_white_p <- Welch_gender_white$p.value
Welch_gender_white_meandif <- abs(Welch_gender_white$estimate[1]-Welch_gender_white$estimate[2])
group1_mean<- Welch_gender_white$estimate[1]
group2_mean <- Welch_gender_white$estimate[2]
df_group1_mean <- as.data.frame(group1_mean)
ci.lower = abs(Welch_gender_white$conf.int[1])
ci.upper = abs(Welch_gender_white$conf.int[2])
```

```{r}
Welch.test.check <- function(df_name, dependent, var1){
  # defining the objects
  dependent <- df_name[dependent]
  variable1 <- df_name[var1]
  df <- data.frame(dependent=unlist(dependent),
                   variable1=unlist(variable1))
  
  # generating statistic
  Welchstats <- t.test(dependent~variable1, data=df)
  print(Welchstats)
  Welch.pvalue <- Welchstats$p.value
  
  # generate message about next steps
  if(Welch.pvalue< 0.01){
    print(paste0("Based on these results, the p-value is statistically significant (p<0.01), which means that there is a significant difference between the variances of these two groups"))
    } else if (Welch.pvalue< 0.05){
      print(paste0("Based on these results, the p-value is statistically significant (p<0.05), which means that there is a significant difference between the variances of these two groups"))
    } else if (Welch.pvalue>= 0.05){
      print(paste0("Based on these results, there is no significant difference between the two groups."))
    } else {NULL}
  }

```

```{r}
# use function with inputs
Welch.test.check(comp_gender_white, "commute_auto_Distance", "gender")
```
\
\
<span style="color:#F05A28">*Asian POC*</span>

1. F-test
```{r}
# set up data
comp_gender_asian <- not_home_workers %>%
  dplyr::filter(gender=="Female" | gender=="Male") %>%
  dplyr::filter(race_category=="Asian") %>% 
  dplyr::select(gender, commute_auto_Distance)
```

```{r}
# test variance
F.test.check(comp_gender_asian, "commute_auto_Distance", "gender")
```
\

2. T-test Test
```{r, include=FALSE, eval=FALSE}
T_gender_asian <- t.test(commute_auto_Distance~gender,
       data=comp_gender_asian,
       var.equal=TRUE)
T_gender_asian
T_gender_asian_p <- T_gender_asian$p.value
T_gender_asian_meandif <- abs(T_gender_asian$estimate[1]-T_gender_asian$estimate[2])
```

```{r}
T.test.check <- function(df_name, dependent, var1){
  # defining the objects
  dependent <- df_name[dependent]
  variable1 <- df_name[var1]
  df <- data.frame(dependent=unlist(dependent),
                   variable1=unlist(variable1))
  
  # generating statistic
  Tteststats <- t.test(dependent~variable1, data=df, var.equal=TRUE)
  print(Tteststats)
  Ttest.pvalue <- Tteststats$p.value
  
  # generate message about next steps
  if(Ttest.pvalue< 0.01){
    print(paste0("Based on these results, the p-value is statistically significant (p<0.01), which means that there is a significant difference between the variances of these two groups"))
    } else if (Ttest.pvalue< 0.05){
      print(paste0("Based on these results, the p-value is statistically significant (p<0.05), which means that there is a significant difference between the variances of these two groups"))
    } else if (Ttest.pvalue>= 0.05){
      print(paste0("Based on these results, there is no significant difference between the two groups."))
    } else {NULL}
  }

```

```{r}
# use function with inputs
T.test.check(comp_gender_asian, "commute_auto_Distance", "gender")
```